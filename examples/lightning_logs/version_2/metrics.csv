epoch,step,train_loss
1,99,768.5411376953125
2,199,793.4610595703125
4,299,725.32861328125
5,399,658.924072265625
6,499,737.603271484375
8,599,732.89013671875
9,699,620.1419067382812
10,799,733.874267578125
12,899,741.5294189453125
13,999,735.543212890625
14,1099,737.6181030273438
16,1199,707.9515380859375
17,1299,748.8779907226562
18,1399,749.96337890625
20,1499,711.9371337890625
21,1599,716.72314453125
22,1699,699.3619384765625
24,1799,732.9623413085938
25,1899,691.518798828125
27,1999,706.9657592773438
28,2099,751.517578125
29,2199,723.541748046875
31,2299,789.436767578125
32,2399,726.7177734375
33,2499,695.380615234375
35,2599,733.4761962890625
36,2699,740.739501953125
37,2799,749.169677734375
39,2899,720.8021240234375
40,2999,741.804931640625
41,3099,690.1448974609375
43,3199,682.3551025390625
44,3299,718.9022216796875
45,3399,687.742431640625
47,3499,691.7247314453125
48,3599,737.0232543945312
49,3699,363.83349609375
51,3799,725.0728759765625
52,3899,696.2797241210938
54,3999,739.9466552734375
55,4099,716.227294921875
56,4199,708.3482666015625
58,4299,665.0849609375
59,4399,717.4241333007812
60,4499,710.1725463867188
62,4599,712.9649658203125
63,4699,644.3447875976562
64,4799,703.6712646484375
66,4899,696.4082641601562
67,4999,704.9036254882812
68,5099,666.2867431640625
70,5199,704.7554321289062
71,5299,730.6514892578125
72,5399,665.8707275390625
74,5499,683.1373291015625
75,5599,716.9430541992188
77,5699,634.3733520507812
78,5799,747.888427734375
79,5899,697.5850830078125
81,5999,695.9131469726562
82,6099,728.7745361328125
83,6199,716.5146484375
85,6299,743.423095703125
86,6399,643.3201293945312
87,6499,736.6299438476562
89,6599,708.457275390625
90,6699,738.720947265625
91,6799,727.6487426757812
93,6899,703.720947265625
94,6999,753.8397216796875
95,7099,750.72509765625
97,7199,715.1366577148438
98,7299,735.6810302734375
99,7399,416.410400390625
